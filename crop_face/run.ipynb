{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras.applications import VGG16\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import cv2\n",
    " \n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    " \n",
    "train_dir = os.path.join('./Dataset/Train')\n",
    "val_dir = os.path.join('./Dataset/Validation')\n",
    "test_dir = os.path.join('./Dataset/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size=4, target_size=(220, 200), color_mode='rgb',class_mode='categorical')\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, batch_size=3, target_size=(220, 200), color_mode='rgb',class_mode='categorical')\n",
    "test_set = test_datagen.flow_from_directory(test_dir, target_size=(220, 200),batch_size=1, class_mode='categorical', save_to_dir='./' , save_prefix='test', save_format='png',class_mode='categorical')\n",
    "\n",
    "input_tensor = Input(shape=(220, 200, 3), dtype='float32', name='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(220, 200, 3))\n",
    "pre_trained_vgg.trainable = False\n",
    "# pre_trained_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_model = models.Sequential()\n",
    "additional_model.add(pre_trained_vgg)\n",
    "additional_model.add(layers.Flatten())\n",
    "additional_model.add(layers.Dense(4096, activation='relu'))\n",
    "additional_model.add(layers.Dense(2048, activation='relu'))\n",
    "additional_model.add(layers.Dense(1024, activation='relu'))\n",
    "additional_model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='pretrained_VGG_weight.hdf5', \n",
    "            monitor='loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)\n",
    " \n",
    "additional_model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=2e-5), metrics=['acc'])\n",
    "\n",
    "\n",
    "history = additional_model.fit_generator(train_generator, \n",
    "            steps_per_epoch=math.ceil(train_generator.n / train_generator.batch_size), \n",
    "            epochs=50, \n",
    "            validation_data=val_generator, \n",
    "            validation_steps=math.ceil(val_generator.n / val_generator.batch_size), \n",
    "            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_model = load_model('pretrained_VGG_weight.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "img, label = test_set.next()\n",
    "n_img = len(label)\n",
    "\n",
    "base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "for idx in range(n_img - 1):\n",
    "    img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "    base = np.hstack((base, img2))\n",
    "images.append(base)\n",
    "images = np.concatenate(images)\n",
    "img_test_a = np.uint8(images*255) \n",
    "img = images[0]\n",
    "# cv2.imwrite('./test_1.jpg',img_test_a)\n",
    "for idx in range(len(images) - 1):\n",
    "    img = np.vstack((img, images[idx + 1]))\n",
    "    # img = np.hstack((img, images[idx + 1]))\n",
    "# cv2.imshow('result', img)\n",
    "# cv2.imwrite('./test.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarocat",
   "language": "python",
   "name": "tarocat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
