{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97542f2ccc13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m375\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m667\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (width, height)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'src'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# open video file\n",
    "video_path = 'iu_youandme.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "output_size = (375, 667) # (width, height)\n",
    "fit_to = 'height'\n",
    "\n",
    "# initialize writing video\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('%s_output.mp4' % (video_path.split('.')[0]), fourcc, cap.get(cv2.CAP_PROP_FPS), output_size)\n",
    "\n",
    "# check file is opened\n",
    "if not cap.isOpened():\n",
    "  exit()\n",
    "\n",
    "# initialize tracker\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "  \"csrt\": cv2.TrackerCSRT_create,\n",
    "  \"kcf\": cv2.TrackerKCF_create,\n",
    "  \"boosting\": cv2.TrackerBoosting_create,\n",
    "  \"mil\": cv2.TrackerMIL_create,\n",
    "  \"tld\": cv2.TrackerTLD_create,\n",
    "  \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "  \"mosse\": cv2.TrackerMOSSE_create\n",
    "}\n",
    "\n",
    "tracker = OPENCV_OBJECT_TRACKERS['csrt']()\n",
    "\n",
    "# global variables\n",
    "top_bottom_list, left_right_list = [], []\n",
    "count = 0\n",
    "\n",
    "# main\n",
    "ret, img = cap.read()\n",
    "\n",
    "cv2.namedWindow('Select Window')\n",
    "cv2.imshow('Select Window', img)\n",
    "\n",
    "# select ROI\n",
    "rect = cv2.selectROI('Select Window', img, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow('Select Window')\n",
    "\n",
    "# initialize tracker\n",
    "tracker.init(img, rect)\n",
    "\n",
    "while True:\n",
    "    count += 1\n",
    "  # read frame from video\n",
    "    ret, img = cap.read()\n",
    "    ret = cap.set(3,320)\n",
    "    ret = cap.set(4,240)\n",
    "\n",
    "    if not ret:\n",
    "        exit()\n",
    "\n",
    "  # update tracker and get position from new frame\n",
    "    success, box = tracker.update(img)\n",
    "  # if success:\n",
    "    left, top, w, h = [int(v) for v in box]\n",
    "    right = left + w\n",
    "    bottom = top + h\n",
    "\n",
    "  # save sizes of image\n",
    "    top_bottom_list.append(np.array([top, bottom]))\n",
    "    left_right_list.append(np.array([left, right]))\n",
    "\n",
    "  # use recent 10 elements for crop (window_size=10)\n",
    "    if len(top_bottom_list) > 10:\n",
    "        del top_bottom_list[0]\n",
    "        del left_right_list[0]\n",
    "\n",
    "  # compute moving average\n",
    "        avg_height_range = np.mean(top_bottom_list, axis=0).astype(np.int)\n",
    "        avg_width_range = np.mean(left_right_list, axis=0).astype(np.int)\n",
    "        avg_center = np.array([np.mean(avg_width_range), np.mean(avg_height_range)]) # (x, y)\n",
    "\n",
    "  # compute scaled width and height\n",
    "        scale = 1.3\n",
    "        avg_height = (avg_height_range[1] - avg_height_range[0]) * scale\n",
    "        avg_width = (avg_width_range[1] - avg_width_range[0]) * scale\n",
    "\n",
    "  # compute new scaled ROI\n",
    "        avg_height_range = np.array([avg_center[1] - avg_height / 2, avg_center[1] + avg_height / 2])\n",
    "        avg_width_range = np.array([avg_center[0] - avg_width / 2, avg_center[0] + avg_width / 2])\n",
    "\n",
    "  # fit to output aspect ratio\n",
    "    if fit_to == 'width':\n",
    "        avg_height_range = np.array([\n",
    "        avg_center[1] - avg_width * output_size[1] / output_size[0] / 2,\n",
    "        avg_center[1] + avg_width * output_size[1] / output_size[0] / 2\n",
    "        ]).astype(np.int).clip(0, 9999)\n",
    "        avg_width_range = avg_width_range.astype(np.int).clip(0, 9999)\n",
    "    elif fit_to == 'height':\n",
    "        avg_height_range = avg_height_range.astype(np.int).clip(0, 9999)\n",
    "\n",
    "        avg_width_range = np.array([\n",
    "        avg_center[0] - avg_height * output_size[0] / output_size[1] / 2,\n",
    "        avg_center[0] + avg_height * output_size[0] / output_size[1] / 2\n",
    "        ]).astype(np.int).clip(0, 9999)\n",
    "\n",
    "  # crop image\n",
    "        result_img = img[avg_height_range[0]:avg_height_range[1], avg_width_range[0]:avg_width_range[1]].copy()\n",
    "\n",
    "  # resize image to output size\n",
    "        result_img = cv2.resize(result_img, output_size)\n",
    "\n",
    "  # visualize\n",
    "        pt1 = (int(left), int(top))\n",
    "        pt2 = (int(right), int(bottom))\n",
    "        cv2.rectangle(img, pt1, pt2, (255, 255, 255), 3)\n",
    "\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.imshow('result', result_img)\n",
    "  # write video\n",
    "        out.write(result_img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarocat=3.6",
   "language": "python",
   "name": "tarocat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
