{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### 객체 추적과 모션 벡터 ###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 배경 차분 : 정적 배경 차분\n",
    "# 등록된 배경 모델과 현재 입력 프레임과의 차영상을 이용하여 전경 객체를 검출\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture('PETS2000.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 배경 영상 등록\n",
    "ret, back = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print('Background image registration failed!')\n",
    "    sys.exit()\n",
    "\n",
    "back = cv2.cvtColor(back, cv2.COLOR_BGR2GRAY)\n",
    "back = cv2.GaussianBlur(back, (0, 0), 1.0)\n",
    "\n",
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (0, 0), 1.0)\n",
    "\n",
    "    # 차영상 구하기 & 이진화\n",
    "    diff = cv2.absdiff(gray, back)\n",
    "    _, diff = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('diff', diff)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 배경 차분: 이동 평균 배경\n",
    "# 이동 평균 - 수백 장의 영상을 저장하는 대신 매 프레임이 들어올 때마다 평균 영상을 갱신\n",
    "# cv2.accumulateWeighted(src, dst, alpha, mask=None) -> dst\n",
    "# src: 입력 영상, 1또는 3채널, 8비트 또는 32비트 실수형\n",
    "# dst: 축적 영상, 입력 영상과 동일 채널 개수\n",
    "# alpha: (입력 영상에 대한) 가중치\n",
    "# mask: 마스크 영상\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture('PETS2000.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 배경 영상 등록\n",
    "ret, back = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print('Background image registration failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# back: uint8 배경, fback: float32 배경\n",
    "back = cv2.cvtColor(back, cv2.COLOR_BGR2GRAY)\n",
    "back = cv2.GaussianBlur(back, (0, 0), 1.0)\n",
    "fback = back.astype(np.float32)\n",
    "\n",
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (0, 0), 1.0)\n",
    "\n",
    "    # fback: float32, back: uint8 배경\n",
    "    cv2.accumulateWeighted(gray, fback, 0.01)\n",
    "    back = fback.astype(np.uint8)\n",
    "\n",
    "    diff = cv2.absdiff(gray, back)\n",
    "    _, diff = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 레이블링을 이용하여 바운딩 박스 표시\n",
    "    cnt, _, stats, _ = cv2.connectedComponentsWithStats(diff)\n",
    "\n",
    "    for i in range(1, cnt):\n",
    "        x, y, w, h, s = stats[i]\n",
    "\n",
    "        if s < 100:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('diff', diff)\n",
    "    cv2.imshow('back', back)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 배경 차분: MOG 배경 모델\n",
    "# MOG란 각 픽셀에 대해 MOG 확률 모델을 설정하여 배경과 전경을 구분\n",
    "# static Scene -> Single Gaussian model -> Gaussian mixture model -> Adaptive Gaussian mixture model\n",
    "# cv2.BackgroundSubtractor\n",
    "# cv2.createBackgroundSubtractorMOG2(, history=None, varThreshold=None, detectShadows=None) -> dst\n",
    "# history: 히스토리 길이, 기본값은 500\n",
    "# varThreshold: 픽셀과 모델 사이의 마할라노비스 거리 제곱에 대한 임계값, 해당 픽셀이 배경 모델에 의해 잘 표현되는 지를 판단 기본값은 16\n",
    "# detectShadows: 그림자 검출 여부, 기본값은 True\n",
    "\n",
    "# cv2.BackgroundSubtractor.apply(image, fgmask=None, learningRate=None) -> fgmask\n",
    "# image: (입력) 다음 비디오 프레임\n",
    "# fgmask: (출력) 전경 마스크 영상, 8비트 이진 영상\n",
    "# learningRate: 배경 모델 학습 속도 지정(0~1 사이의 실수) 기본값은 -1(auto)\n",
    "# 배경 영상 반환 함수 -> cv2.BackgroundSubtractor.getBackgroundImage(, backgroundImage=None)\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture('PETS2000.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 배경 차분 알고리즘 객체 생성\n",
    "bs = cv2.createBackgroundSubtractorMOG2()\n",
    "#bs = cv2.createBackgroundSubtractorKNN()\n",
    "#bs.setDetectShadows(False)\n",
    "\n",
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fgmask = bs.apply(gray)\n",
    "    back = bs.getBackgroundImage()\n",
    "\n",
    "    # 레이블링을 이용하여 바운딩 박스 표시\n",
    "    cnt, _, stats, _ = cv2.connectedComponentsWithStats(fgmask)\n",
    "\n",
    "    for i in range(1, cnt):\n",
    "        x, y, w, h, s = stats[i]\n",
    "\n",
    "        if s < 80:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('back', back)\n",
    "    cv2.imshow('fgmask', fgmask)\n",
    "\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 이동 알고리즘\n",
    "# 모드 검출 알고리즘\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture('camshift.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 초기 사각형 영역: (x, y, w, h)\n",
    "x, y, w, h = 135, 220, 100, 100\n",
    "rc = (x, y, w, h)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print('frame read failed!')\n",
    "    sys.exit()\n",
    "\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HS 히스토그램 계산\n",
    "channels = [0, 1]\n",
    "ranges = [0, 180, 0, 256]\n",
    "hist = cv2.calcHist([roi_hsv], channels, None, [90, 128], ranges)\n",
    "\n",
    "# Mean Shift 알고리즘 종료 기준\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # HS 히스토그램에 대한 역투영\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    backproj = cv2.calcBackProject([frame_hsv], channels, hist, ranges, 1)\n",
    "\n",
    "    # Mean Shift\n",
    "    _, rc = cv2.meanShift(backproj, rc, term_crit)\n",
    "\n",
    "    # 추적 결과 화면 출력\n",
    "    cv2.rectangle(frame, rc, (0, 0, 255), 2)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(60) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 캠시프트 알고리즘\n",
    "# 캠시프트란 추적하는 객체의 크기가 변하더라도 검색 윈도우의 크기가 고정되어 있는 평균 이동 알고리즘의 단점을 보완\n",
    "# cv2.CamShift(probImage, window, criteria) -> retval, window\n",
    "# probImage: 관심 객체에 대한 히스토그램 역투영 영상(확률 영상)\n",
    "# window: 초기 검색 영역 윈도우 & 결과 영역 반환\n",
    "# criteria: 알고리즘 종료 기준, (type, maxCount, epsilon) 튜플 -> 최대 10번 반복하며 정확도가 1이하면 (즉, 이동 크기가 1픽셀보다 작으면) 종료\n",
    "# retval: 추적하는 객체의 모양을 나타내는 회전된 사각형 정보를 반환 ((cx,cy), (width, height), angle) 튜플\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture('camshift.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 초기 사각형 영역: (x, y, w, h)\n",
    "x, y, w, h = 135, 220, 100, 100\n",
    "rc = (x, y, w, h)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print('frame read failed!')\n",
    "    sys.exit()\n",
    "\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HS 히스토그램 계산\n",
    "channels = [0, 1]\n",
    "ranges = [0, 180, 0, 256]\n",
    "hist = cv2.calcHist([roi_hsv], channels, None, [90, 128], ranges)\n",
    "\n",
    "# CamShift 알고리즘 종료 기준\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # HS 히스토그램에 대한 역투영\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    backproj = cv2.calcBackProject([frame_hsv], channels, hist, ranges, 1)\n",
    "\n",
    "    # CamShift\n",
    "    ret, rc = cv2.CamShift(backproj, rc, term_crit)\n",
    "\n",
    "    # 추적 결과 화면 출력\n",
    "    cv2.rectangle(frame, rc, (0, 0, 255), 2)\n",
    "    cv2.ellipse(frame, ret, (0, 255, 0), 2)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(60) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 옵티컬 플로우 - 연속하는 두 프레임(영상)에서 카메라 또는 객체의 움직임에 의해 나타나는 객체의 이동 정보 패턴\n",
    "# 루카스-카나데 알고리즘 vs 파네백 알고리즘\n",
    "# cv2.calcOpticalFlowFarneback()\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src1 = cv2.imread('frame1.jpg')\n",
    "src2 = cv2.imread('frame2.jpg')\n",
    "\n",
    "if src1 is None or src2 is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "gray1 = cv2.cvtColor(src1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "pt1 = cv2.goodFeaturesToTrack(gray1, 50, 0.01, 10)\n",
    "pt2, status, err = cv2.calcOpticalFlowPyrLK(src1, src2, pt1, None)\n",
    "\n",
    "dst = cv2.addWeighted(src1, 0.5, src2, 0.5, 0)\n",
    "\n",
    "for i in range(pt2.shape[0]):\n",
    "    if status[i, 0] == 0:\n",
    "        continue\n",
    "\n",
    "    cv2.circle(dst, tuple(pt1[i, 0]), 4, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.circle(dst, tuple(pt2[i, 0]), 4, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.arrowedLine(dst, tuple(pt1[i, 0]), tuple(pt2[i, 0]), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Camera open failed!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 카메라 장치 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 설정 변수 정의\n",
    "MAX_COUNT = 50\n",
    "needToInit = False\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
    "          (0, 255, 255), (255, 0, 255), (128, 255, 0), (0, 128, 128)]\n",
    "\n",
    "ptSrc = None\n",
    "ptDst = None\n",
    "\n",
    "# 카메라 매 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img = frame.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if needToInit:\n",
    "        ptSrc = cv2.goodFeaturesToTrack(gray, 50, 0.01, 10)\n",
    "        needToInit = False\n",
    "\n",
    "    if ptSrc is not None:\n",
    "        if prev is None:\n",
    "            prev = gray.copy()\n",
    "\n",
    "        ptDst, status, _ = cv2.calcOpticalFlowPyrLK(prev, gray, ptSrc, None)\n",
    "\n",
    "        for i in range(ptDst.shape[0]):\n",
    "            if status[i, 0] == 0:\n",
    "                continue\n",
    "\n",
    "            cv2.circle(img, tuple(ptDst[i, 0]), 4, colors[i % 8], 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        needToInit = not needToInit\n",
    "    elif key == ord('c'):\n",
    "        ptSrc = None\n",
    "        ptDst = None\n",
    "\n",
    "    ptDst, ptSrc = ptSrc, ptDst\n",
    "    prev = gray\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow\n",
    "# prev, nex: 이전 영상과 현재 영상, 그레이스케일 영상\n",
    "# flow: (출력) 계산된 옵티컬 플로우, np.ndarray. shape=(h,w,2), dtype=np.float32\n",
    "# pyr_scale: 피라미드 영상을 만들 때 축소 비율 (e.g.) 0.5\n",
    "# levels: 피라미드 영상 개수 (e.g.) 3\n",
    "# winsize: 평균 윈도우 크기(e.g.) 13\n",
    "# iterations: 각 피라미드 레벨에서 알고리즘 반복 횟수, (e.g.) 10\n",
    "# poly_n: 다항식 확장을 위한 이웃 픽셀 크기, 보통 5 또는 7\n",
    "# poly_sigma: 가우시안 표준편차, 보통 poly_n = 5면 1.1, poly_n =7 이면 1.5\n",
    "# flags: 0, cv2.OPTFLOW_USE_INITIAL_FLOW, cv2.OPTFLOW_FARNEBACK_GAUSSIAN\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"vtest.avi\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print('frame read failed!')\n",
    "    sys.exit()\n",
    "\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print('frame read failed!')\n",
    "        sys.exit()\n",
    "\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 13, 3, 5, 1.1, 0)\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang*180/np.pi/2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('frame', frame2)\n",
    "    cv2.imshow('flow', bgr)\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "    gray1 = gray2\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def draw_flow(img, flow, step=16):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.polylines(vis, lines, 0, (0, 255, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "    for (x1, y1), (_x2, _y2) in lines:\n",
    "        cv2.circle(vis, (x1, y1), 1, (0, 128, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return vis\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('vtest.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print('frame read failed!')\n",
    "    sys.exit()\n",
    "\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print('frame read failed!')\n",
    "        sys.exit()\n",
    "\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 13, 3, 5, 1.1, 0)\n",
    "\n",
    "    cv2.imshow('frame2', draw_flow(gray2, flow))\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "    gray1 = gray2\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'TrackerCSRT_create'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5bc4a7051f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Discriminative Correlation Filter with Channel and Spatial Reliability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mtracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrackerCSRT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# 첫 번째 프레임에서 추적 ROI 설정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'TrackerCSRT_create'"
     ]
    }
   ],
   "source": [
    "# OpenCV 트래커\n",
    "# opencv 3.0 부터 트래커 클래스 제공\n",
    "# opencv-contrib-python==4.1.0.25\n",
    "# OpenCV 4.1 기준으로 8가지 트래킹 기능 제공\n",
    "# cv2.TrackerXXX_create() -> XXX, Boosting, CSRT, GOTURN, KCF, MedianFlow, MIL, MOSSE, TLD\n",
    "# cv2.Tracker.init(image, boundingBox) -> retval\n",
    "# cv2.Tracker.update(image) -> retval, boundingBox\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 동영상 열기\n",
    "cap = cv2.VideoCapture('tracking1.mp4')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 트래커 객체 생성\n",
    "\n",
    "# Kernelized Correlation Filters\n",
    "#tracker = cv2.TrackerKCF_create()\n",
    "\n",
    "# Minimum Output Sum of Squared Error\n",
    "#tracker = cv2.TrackerMOSSE_create()\n",
    "\n",
    "# Discriminative Correlation Filter with Channel and Spatial Reliability\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "\n",
    "# 첫 번째 프레임에서 추적 ROI 설정\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print('Frame read failed!')\n",
    "    sys.exit()\n",
    "\n",
    "rc = cv2.selectROI('frame', frame)\n",
    "tracker.init(frame, rc)\n",
    "\n",
    "# 매 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print('Frame read failed!')\n",
    "        sys.exit()\n",
    "\n",
    "    # 추적 & ROI 사각형 업데이트\n",
    "    ret, rc = tracker.update(frame)\n",
    "    rc = tuple([int(_) for _ in rc])\n",
    "    cv2.rectangle(frame, rc, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### 머신러닝 ###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.ml_StatModel\n",
    "    # cv2.ml_ANN_MLP\n",
    "    # cv2.ml_DTrees\n",
    "    #     cv2.ml_Boost\n",
    "    #     cv2.ml_RTrees\n",
    "    # cv2.ml_EM\n",
    "    # cv2.ml_KNearest\n",
    "    # cv2.ml_LogisticRegression\n",
    "    # cv2.ml_NormalBayesClassifier\n",
    "    # cv2.ml_SVM\n",
    "    # cv2.ml_SVMSDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### 딥러닝 이해와 영상 인식 ###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### 딥러닝 활용 : 객체 검출, 포즈 인식 ###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}